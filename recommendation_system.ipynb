%%writefile recommendation_system.ipynb
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "## Collaborative Filtering with Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-surprise pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import requests\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download and Prepare Dataset\n",
    "Using MovieLens 100K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "DATASET_URL = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "DATA_DIR = \"ml-100k\"\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    r = requests.get(DATASET_URL)\n",
    "    with open(\"ml-100k.zip\", \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    \n",
    "    with ZipFile(\"ml-100k.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\".\")\n",
    "\n",
    "# Load ratings data\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"u.data\"),\n",
    "    sep=\"\\t\",\n",
    "    names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "# Load movie metadata\n",
    "movies = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"u.item\"),\n",
    "    sep=\"|\",\n",
    "    encoding=\"latin-1\",\n",
    "    names=[\"item_id\", \"title\", \"release_date\", \"video_release\", \"imdb_url\", \n",
    "           \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\",\n",
    "           \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "           \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    ")[[\"item_id\", \"title\"]]\n",
    "\n",
    "print(f\"Dataset size: {ratings.shape[0]} ratings\")\n",
    "print(f\"Users: {ratings['user_id'].nunique()}\")\n",
    "print(f\"Movies: {ratings['item_id'].nunique()}\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='rating', data=ratings, palette='viridis')\n",
    "plt.title('Rating Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Ratings per user\n",
    "user_ratings = ratings.groupby('user_id').size()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(user_ratings, bins=50, kde=True)\n",
    "plt.title('Ratings per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Ratings per movie\n",
    "movie_ratings = ratings.groupby('item_id').size()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(movie_ratings, bins=50, kde=True)\n",
    "plt.title('Ratings per Movie')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[[\"user_id\", \"item_id\", \"rating\"]], reader)\n",
    "\n",
    "# Split data\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize and train SVD model\n",
    "model = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42)\n",
    "model.fit(trainset)\n",
    "\n",
    "# Cross-validation\n",
    "cv_results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set evaluation\n",
    "from surprise import accuracy\n",
    "predictions = model.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# Cross-validation results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average RMSE: {np.mean(cv_results['test_rmse']):.4f}\")\n",
    "print(f\"Average MAE: {np.mean(cv_results['test_mae']):.4f}\")\n",
    "\n",
    "# Precision and Recall\n",
    "from surprise import accuracy\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    \n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "    \n",
    "    return precisions, recalls\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "print(f\"Precision@5: {np.mean(list(precisions.values())):.4f}\")\n",
    "print(f\"Recall@5: {np.mean(list(recalls.values())):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(model, user_id, n=10):\n",
    "    # Get list of all movie IDs\n",
    "    all_movie_ids = ratings['item_id'].unique()\n",
    "    \n",
    "    # Get movies user has already rated\n",
    "    rated_movies = ratings[ratings['user_id'] == user_id]['item_id'].values\n",
    "    \n",
    "    # Predict ratings for unrated movies\n",
    "    predictions = []\n",
    "    for movie_id in all_movie_ids:\n",
    "        if movie_id not in rated_movies:\n",
    "            pred = model.predict(user_id, movie_id)\n",
    "            predictions.append((movie_id, pred.est))\n",
    "    \n",
    "    # Sort predictions by estimated rating\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top N recommendations\n",
    "    top_n = predictions[:n]\n",
    "    \n",
    "    # Convert to DataFrame with movie titles\n",
    "    top_n_df = pd.DataFrame(top_n, columns=['item_id', 'estimated_rating'])\n",
    "    top_n_df = pd.merge(top_n_df, movies, on='item_id')\n",
    "    \n",
    "    return top_n_df\n",
    "\n",
    "# Example: Get recommendations for user 196\n",
    "user_id = 196\n",
    "print(f\"\\nTop 10 Recommendations for User {user_id}:\")\n",
    "get_top_n_recommendations(model, user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'movie_recommender.pkl')\n",
    "print(\"Model saved as movie_recommender.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
